<a href="http://www.insa-toulouse.fr/" ><img src="http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg" height="100"  alt="INSA"/></a> 
# Evaluation des Risques Sociétaux des Algorithmes d'IA: ressources pédagogiques


#### [Philippe Besse](https://www.math.univ-toulouse.fr/~besse/) 

*Université de Toulouse -- INSA; Institut de Mathématiques -- UMR CNRS 5219  & [ObvIA](https://observatoire-ia.ulaval.ca/)* -- Université Laval.

### Présentation

Suite à la publication du livre blanc pour une [approche de l'IA basée sur l'excellence et la confiance](https://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_fr.pdf) (2020), la Commission Européenne (CE) a publié de nombreuses propositions de textes réglementaires dont un [*AI Act*](https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-european-approach-artificial-intelligence) (2021) établissant des *règles harmonisées sur l'intelligence artificielle* (IA). Quels seront les conséquences et impacts de l'adoption à venir de ce texte du point de vue d'un mathématicien ou plutôt statisticien impliqué dans la conception de système d'intelligence artificielle (IA) à haut risque au sens de la CE? Quels outils et méthodes vont permettre de répondre à l'obligation d'une analyse rigoureuse et documentée des données traitées, des performances, robustesse, résilience de l'algorithme, de son explicabilité, des risques, pour les droits fondamentaux, de biais discriminatoires? 

- Besse et al. (2019) analysent les différentes sources de risque: défaillances, opacité, discrimination des algorithmes d'apprentissage statistique.

- Besse et al. (2020) applique ces réflexions au déploiement des algorithmes d'IA en Santé.

- Besse (2021) illustre ces questions par un exemple numérique analogue à un score de crédit (cf. [tutoriel](https://github.com/wikistat/Fair-ML-4-Ethical-AI/blob/master/AdultCensus/AdultCensus-R-biasDetection.ipynb)) à la recherche d'un moins mauvais compromis entre toutes les contraintes puis conclut sur les avancées et limites du projet de règlement européen pour les systèmes d'IA à haut risque.

Ce dépôt regroupe les ressources pédagogiques (données, fonctions, calepins jupyter) permettant l'exécution du  [tutoriel](https://github.com/wikistat/Fair-ML-4-Ethical-AI/blob/master/AdultCensus/AdultCensus-R-biasDetection.ipynb), accompagnant l'article Besse et al. (2021) et reproduisant les résultats de Besse (2021).


### Références

- Besse P., Castets-Renard C., Garivier A., Loubes J.-M. (2019). [L'IA du Quotidien peut elle être Éthique? Loyauté des Algorithmes d'Apprentissage Automatique](http://statistique-et-societe.fr/article/view/719), *Statistique et Société*, Vol6 (3), pp 9-31. 

- Besse P. Besse-Patin A., Castets-Renard C. (2020). [Implications juridiques et éthiques des algorithmes d'intelligence artificielle dans le domaine de la santé](http://statistique-et-societe.fr/article/view/801), *Statistique & Société*, 3, pp 21-53.

- Besse P. (2021). [Statistique & Règlement Européen des Systèmes d'IA (AI Act)](https://hal.archives-ouvertes.fr/hal-03253111), preprint, HAL-03253111.

- Besse P. del Barrio E. Gordaliza P. Loubes J.-M., Risser L. (2021). [A survey of bias in Machine Learning through the prism of Statistical Parity for the Adult Data Set](https://doi.org/10.1080/00031305.2021.1952897), *The American Statistician*, DOI: 10.1080/00031305.2021.1952897 [Open access version](https://arxiv.org/pdf/2003.14263.pdf). 

